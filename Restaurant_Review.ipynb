{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Liked\n",
      "0                           Wow... Loved this place.      1\n",
      "1                                 Crust is not good.      0\n",
      "2          Not tasty and the texture was just nasty.      0\n",
      "3  Stopped by during the late May bank holiday of...      1\n",
      "4  The selection on the menu was great and so wer...      1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('/Users/rishika/Desktop/Restaurant_Reviews.tsv', sep = '\\\\t', quoting = 3, engine= \"python\")\n",
    "\n",
    "\n",
    "print(dataset.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive reviews = 500\n",
      "This is a balanced dataset with equal number of positive and negative reviews\n"
     ]
    }
   ],
   "source": [
    "positive_review_count=0\n",
    "for i in range (0,1000):\n",
    "    if dataset.iloc[i,1] == 1:\n",
    "        positive_review_count= positive_review_count+1\n",
    "print(\"The number of positive reviews = \"+ str(positive_review_count) )       \n",
    "print(\"This is a balanced dataset with equal number of positive and negative reviews\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rishika/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wow love place', 'crust good', 'tasti textur nasti', 'stop late may bank holiday rick steve recommend love', 'select menu great price']\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "#Iterate over all the reviews in the dataset\n",
    "for i in range(0,1000):\n",
    "    \n",
    "    #1. Remove all the non-text elements from the review like emoticons, exclamatory mark, etc\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    \n",
    "    #2. Convert the text to lower case.\n",
    "    review = review.lower()\n",
    "\n",
    "    #3. split the review to match the words from the stop word list and remove the words not required.\n",
    "    #4. PorterStemmer is used to obtain the root word of all the words, eg loved, loving will become love.\n",
    "\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words(\"english\"))]\n",
    "\n",
    "    #5 after performing all the operations join the words back to apply machine learning.\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "\n",
    "print(corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Creating bag of words model.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:,1].values\n",
    "print(X[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test= train_test_split(X,y,test_size=.20, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting Naive Bayes to training set\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier_NB = GaussianNB()\n",
    "classifier_NB.fit(X_train,y_train)\n",
    "\n",
    "#predicting the test set results\n",
    "\n",
    "y_pred_NB = classifier_NB.predict(X_test)\n",
    "\n",
    "#Making Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_NB= confusion_matrix(y_test,y_pred_NB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 42]\n",
      " [12 91]]\n"
     ]
    }
   ],
   "source": [
    "print(cm_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_DT = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier_DT.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_DT = classifier_DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_DT= confusion_matrix(y_test,y_pred_DT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 23]\n",
      " [35 68]]\n"
     ]
    }
   ],
   "source": [
    "print(cm_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Kernel SVM to the Training set\n",
    "# from sklearn.svm import SVC\n",
    "# classifier_SVM = SVC(kernel = 'rbf', random_state = 0)\n",
    "# classifier_SVM.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier_SVM = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_SVM = classifier_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 23]\n",
      " [33 70]]\n"
     ]
    }
   ],
   "source": [
    "cm_svm= confusion_matrix(y_test,y_pred_SVM)\n",
    "print(cm_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_RF = RandomForestClassifier(n_estimators = 500, criterion = 'entropy', random_state = 0)\n",
    "classifier_RF.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_RF = classifier_RF.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88  9]\n",
      " [47 56]]\n"
     ]
    }
   ],
   "source": [
    "cm_RF= confusion_matrix(y_test,y_pred_RF)\n",
    "Accuracy_RF = ((cm_RF[0,0]+ cm_RF[1,1])/ len(y_test))\n",
    "print(cm_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_NB = ((cm_NB[0,0]+ cm_NB[1,1])/ len(y_test))\n",
    "Precision_NB = cm_NB[0,0] / (cm_NB[0,0] + cm_NB[0,1])\n",
    "Recall_NB = cm_NB[0,0] / (cm_NB[0,0]+ cm_NB[1,1])\n",
    "F1_Score_NB = 2 * Precision_NB * Recall_NB / (Precision_NB + Recall_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Naive Bayes is 0.73\n",
      "Precision using Naive Bayes is 0.5670103092783505\n",
      "Recall using Naive Bayes is 0.3767123287671233\n",
      "F1_Score using Naive Bayes is 0.45267489711934156\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy using Naive Bayes is \"+ str(Accuracy_NB))\n",
    "print(\"Precision using Naive Bayes is \"+ str(Precision_NB))\n",
    "print(\"Recall using Naive Bayes is \"+ str(Recall_NB))\n",
    "print(\"F1_Score using Naive Bayes is \"+ str(F1_Score_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_DT= confusion_matrix(y_test,y_pred_DT)\n",
    "Accuracy_DT = ((cm_DT[0,0]+ cm_DT[1,1])/ len(y_test))\n",
    "Precision_DT = cm_DT[0,0] / (cm_DT[0,0] + cm_DT[0,1])\n",
    "Recall_DT = cm_DT[0,0] / (cm_DT[0,0]+ cm_DT[1,1])\n",
    "F1_Score_DT = 2 * Precision_DT * Recall_DT / (Precision_DT + Recall_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Decision Tree Classifier is 0.71\n",
      "Precision using Decision Tree Classifier is 0.7628865979381443\n",
      "Recall using Decision Tree Classifier is 0.5211267605633803\n",
      "F1_Score using Decision Tree Classifier is 0.6192468619246861\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy using Decision Tree Classifier is \"+ str(Accuracy_DT))\n",
    "print(\"Precision using Decision Tree Classifier is \"+ str(Precision_DT))\n",
    "print(\"Recall using Decision Tree Classifier is \"+ str(Recall_DT))\n",
    "print(\"F1_Score using Decision Tree Classifier is \"+ str(F1_Score_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_svm= confusion_matrix(y_test,y_pred_SVM)\n",
    "Accuracy_SVM = ((cm_svm[0,0]+ cm_svm[1,1])/ len(y_test))\n",
    "Precision_SVM = cm_svm[0,0] / (cm_svm[0,0] + cm_svm[0,1])\n",
    "Recall_SVM = cm_svm[0,0] / (cm_svm[0,0]+ cm_svm[1,1])\n",
    "F1_Score_SVM = 2 * Precision_SVM * Recall_SVM / (Precision_SVM + Recall_SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Support Vector Machine is 0.72\n",
      "Precision using Support Vector Machine is 0.7628865979381443\n",
      "Recall using Support Vector Machine is 0.5138888888888888\n",
      "F1_Score using Support Vector Machine is 0.6141078838174273\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy using Support Vector Machine is \"+ str(Accuracy_SVM))\n",
    "print(\"Precision using Support Vector Machine is \"+ str(Precision_SVM))\n",
    "print(\"Recall using Support Vector Machine is \"+ str(Recall_SVM))\n",
    "print(\"F1_Score using Support Vector Machine is \"+ str(F1_Score_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_RF= confusion_matrix(y_test,y_pred_RF)\n",
    "Accuracy_RF = ((cm_RF[0,0]+ cm_RF[1,1])/ len(y_test))\n",
    "Precision_RF = cm_RF[0,0] / (cm_RF[0,0] + cm_RF[0,1])\n",
    "Recall_RF = cm_RF[0,0] / (cm_RF[0,0]+ cm_RF[1,1])\n",
    "F1_Score_RF = 2 * Precision_RF * Recall_RF / (Precision_RF + Recall_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Random Forest is 0.72\n",
      "Precision using Random Forest is 0.9072164948453608\n",
      "Recall using Random Forest is 0.6111111111111112\n",
      "F1_Score using Random Forest is 0.7302904564315353\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy using Random Forest is \"+ str(Accuracy_RF))\n",
    "print(\"Precision using Random Forest is \"+ str(Precision_RF))\n",
    "print(\"Recall using Random Forest is \"+ str(Recall_RF))\n",
    "print(\"F1_Score using Random Forest is \"+ str(F1_Score_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
